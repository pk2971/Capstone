{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb7d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords  # Make sure to import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be227a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (5.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.3->seaborn) (3.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praharshita/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.12.0)\n",
      "Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8b5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_importance(file_path,N):\n",
    "    # Read the content of the text file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        corpus = [file.read()]\n",
    "\n",
    "    # Assuming 'corpus' is a list of text documents for a particular year\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Get feature names and corresponding TF-IDF scores\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    tfidf_scores = X.sum(axis=0).A1\n",
    "\n",
    "    # Create a dictionary of terms and their TF-IDF scores\n",
    "    term_tfidf = dict(zip(feature_names, tfidf_scores))\n",
    "    top_keywords = sorted(term_tfidf.items(), key=lambda x: x[1], reverse=True)[:N]\n",
    "\n",
    "    #print(top_keywords)\n",
    "\n",
    "    return top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b70ff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "0           hon    0.300230\n",
      "1    government    0.230630\n",
      "2         house    0.203093\n",
      "3         think    0.176115\n",
      "4      question    0.167270\n",
      "..          ...         ...\n",
      "195    military    0.023670\n",
      "196      debate    0.023540\n",
      "197        coal    0.023531\n",
      "198     figures    0.023480\n",
      "199     dealing    0.023455\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/praharshita/Desktop/Capstone/word-embedding-files/1918-1927.txt'\n",
    "features=feature_importance(file_path,200)\n",
    "df = pd.DataFrame(features, columns=['Feature', 'Importance'])\n",
    "print(df)\n",
    "df.to_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1918-1927).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0580c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "0           hon    0.402699\n",
      "1    government    0.218142\n",
      "2        member    0.185402\n",
      "3         right    0.178004\n",
      "4         house    0.172600\n",
      "..          ...         ...\n",
      "195   interests    0.023242\n",
      "196        sure    0.023095\n",
      "197     support    0.023061\n",
      "198   insurance    0.023005\n",
      "199       prime    0.022999\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = '/Users/praharshita/Desktop/Capstone/word-embedding-files/1928-1938.txt'\n",
    "features=feature_importance(file_path,200)\n",
    "#print(feature_importance(file_path,40))\n",
    "df = pd.DataFrame(features, columns=['Feature', 'Importance'])\n",
    "print(df)\n",
    "df.to_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1928-1938).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e356e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "0    government    0.272106\n",
      "1         state    0.218094\n",
      "2     secretary    0.217014\n",
      "3           hon    0.200842\n",
      "4           ask    0.196474\n",
      "..          ...         ...\n",
      "195       child    0.026746\n",
      "196  understand    0.026390\n",
      "197    baroness    0.026084\n",
      "198     housing    0.025966\n",
      "199      months    0.025946\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = '/Users/praharshita/Desktop/Capstone/word-embedding-files/2000-2006.txt'\n",
    "features=feature_importance(file_path,200)\n",
    "#print(feature_importance(file_path,40))\n",
    "df = pd.DataFrame(features, columns=['Feature', 'Importance'])\n",
    "print(df)\n",
    "df.to_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(2000-2006).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4921d3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "0           hon    0.361738\n",
      "1         house    0.299669\n",
      "2    government    0.209759\n",
      "3          said    0.199012\n",
      "4         right    0.177512\n",
      "..          ...         ...\n",
      "195      ground    0.022453\n",
      "196  impossible    0.022410\n",
      "197       small    0.022358\n",
      "198        read    0.022276\n",
      "199      little    0.022032\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = '/Users/praharshita/Desktop/Capstone/word-embedding-files/1800-1899.txt'\n",
    "features=feature_importance(file_path,200)\n",
    "#print(feature_importance(file_path,40))\n",
    "df = pd.DataFrame(features, columns=['Feature', 'Importance'])\n",
    "print(df)\n",
    "df.to_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1800-1899).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba83ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "0           hon    0.354247\n",
      "1    government    0.224782\n",
      "2     secretary    0.196639\n",
      "3         state    0.196035\n",
      "4         right    0.157945\n",
      "..          ...         ...\n",
      "195       terms    0.024343\n",
      "196      making    0.024305\n",
      "197        kind    0.024195\n",
      "198      reason    0.024044\n",
      "199   following    0.023998\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = '/Users/praharshita/Desktop/Capstone/word-embedding-files/1900-1999.txt'\n",
    "features=feature_importance(file_path,200)\n",
    "#print(feature_importance(file_path,40))\n",
    "df = pd.DataFrame(features, columns=['Feature', 'Importance'])\n",
    "print(df)\n",
    "df.to_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1900-1999).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e484f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1800_1899 = pd.read_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1800-1899).csv')\n",
    "df_1900_1999 = pd.read_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1900-1999).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2473a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Feature  Importance1800_1899  Importance1900_1999\n",
      "1        house             0.299669             0.140958\n",
      "46   secretary             0.049492             0.196639\n",
      "3         said             0.199012             0.089871\n",
      "19       state             0.094296             0.196035\n",
      "70       asked             0.037151             0.134066\n",
      "..         ...                  ...                  ...\n",
      "90         pay             0.028505             0.034005\n",
      "81        long             0.030225             0.035422\n",
      "66     certain             0.039595             0.034536\n",
      "101     period             0.025927             0.030468\n",
      "117      small             0.022358             0.026833\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_1800_1899, df_1900_1999, on='Feature', how='inner', suffixes=('1800_1899', '1900_1999'))\n",
    "merged_df['importance_change'] = abs(merged_df['Importance1800_1899'] - merged_df['Importance1900_1999'])\n",
    "\n",
    "# Sort the DataFrame by the importance change in descending order\n",
    "merged_df.sort_values(by='importance_change', ascending=False, inplace=True)\n",
    "\n",
    "# Display the top N words with the greatest change in importance scores\n",
    "top_n_words = 100  # You can adjust this based on your preference\n",
    "print(merged_df.head(top_n_words)[['Feature','Importance1800_1899', 'Importance1900_1999']])\n",
    "merged_df.to_csv('/Users/praharshita/Desktop/Capstone/results/language_change(1800s-1900s).csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99ce87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1900_1999 = pd.read_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1900-1999).csv')\n",
    "df_2000_2006 = pd.read_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(2000-2006).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55146525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Importance1900_1999  Importance2000_2006\n",
      "0            hon             0.354247             0.200842\n",
      "18           ask             0.092588             0.196474\n",
      "8          asked             0.134066             0.031036\n",
      "16         think             0.095592             0.033943\n",
      "5         member             0.146170             0.092620\n",
      "..           ...                  ...                  ...\n",
      "105      ireland             0.034369             0.039463\n",
      "17         years             0.092830             0.087749\n",
      "102          tax             0.034784             0.039681\n",
      "49   authorities             0.060403             0.055685\n",
      "92         total             0.037364             0.032663\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_1900_1999, df_2000_2006, on='Feature', how='inner', suffixes=('1900_1999', '2000_2006'))\n",
    "merged_df['importance_change'] = abs(merged_df['Importance1900_1999'] - merged_df['Importance2000_2006'])\n",
    "\n",
    "# Sort the DataFrame by the importance change in descending order\n",
    "merged_df.sort_values(by='importance_change', ascending=False, inplace=True)\n",
    "\n",
    "# Display the top N words with the greatest change in importance scores\n",
    "top_n_words = 100  # You can adjust this based on your preference\n",
    "print(merged_df.head(top_n_words)[['Feature','Importance1900_1999', 'Importance2000_2006']])\n",
    "merged_df.to_csv('/Users/praharshita/Desktop/Capstone/results/language_change(1900s-2000s).csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d74e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1918_1927 = pd.read_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1918-1927).csv')\n",
    "df_1928_1938 = pd.read_csv('/Users/praharshita/Desktop/Capstone/results/feature_importance(1928-1938).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9dfc652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Importance1918_1927  Importance1928_1938\n",
      "0            hon             0.354247             0.200842\n",
      "18           ask             0.092588             0.196474\n",
      "8          asked             0.134066             0.031036\n",
      "16         think             0.095592             0.033943\n",
      "5         member             0.146170             0.092620\n",
      "..           ...                  ...                  ...\n",
      "105      ireland             0.034369             0.039463\n",
      "17         years             0.092830             0.087749\n",
      "102          tax             0.034784             0.039681\n",
      "49   authorities             0.060403             0.055685\n",
      "92         total             0.037364             0.032663\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_1900_1999, df_2000_2006, on='Feature', how='inner', suffixes=('1918_1927', '1928_1938'))\n",
    "merged_df['importance_change'] = abs(merged_df['Importance1918_1927'] - merged_df['Importance1928_1938'])\n",
    "\n",
    "# Sort the DataFrame by the importance change in descending order\n",
    "merged_df.sort_values(by='importance_change', ascending=False, inplace=True)\n",
    "\n",
    "# Display the top N words with the greatest change in importance scores\n",
    "top_n_words = 100  # You can adjust this based on your preference\n",
    "print(merged_df.head(top_n_words)[['Feature','Importance1918_1927', 'Importance1928_1938']])\n",
    "merged_df.to_csv('/Users/praharshita/Desktop/Capstone/results/language_change_before_after_suffrage).csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234da3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
